{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca1f1e76-aab8-420a-a32b-5e7793b75aef",
   "metadata": {
    "id": "ca1f1e76-aab8-420a-a32b-5e7793b75aef"
   },
   "source": [
    "<h1>Task 8: Word Embedding</h1>\n",
    "\n",
    "<h4> This notebook compares different embedding methods on a simple task (sentiment analysis) <a href=\"https://www.kaggle.com/mksaad/arabic-sentiment-twitter-corpus\">on a small dataset</a>.</h4>\n",
    "\n",
    "<h4>Table of Contents:</h4>\n",
    "<ol>\n",
    "    <li>Load Dataset</li>\n",
    "    <li>Normalize Dataset</li>\n",
    "    <li>Tokenize Dataset</li>\n",
    "    <li>Word Embedding</li>\n",
    "    <li>Train RNN model</li>\n",
    "    <li>Evaluate model</li>\n",
    "</ol>\n",
    "<h4>Embedding Methods:</h4>\n",
    "<ol>\n",
    "    <li>Genism library's Word2Vec implementation (trained from scratch)</li>\n",
    "    <li>Genism library's fasttext implementation (trained from scratch)</li>\n",
    "    <li>AraVec pretrained embeddings</li>\n",
    "    <li>BERT Arabic pretrained model</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44dd0846-7c49-4358-a38a-43ce6c730c37",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "44dd0846-7c49-4358-a38a-43ce6c730c37",
    "outputId": "6777836f-e59e-47f2-9ed2-798a9d92416e"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import glob\n",
    "import gensim\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import shuffle\n",
    "from pyarabic import araby\n",
    "from tensorflow.keras.layers import GRU, Embedding, Dense, Input, InputLayer, Dropout, Bidirectional, BatchNormalization, Flatten, Reshape\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53cd5e5-08d7-4614-97cf-90e86c805069",
   "metadata": {
    "id": "d53cd5e5-08d7-4614-97cf-90e86c805069"
   },
   "source": [
    "<h1>Load Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0753d856-c632-4660-b903-512d7385b43c",
   "metadata": {
    "id": "0753d856-c632-4660-b903-512d7385b43c"
   },
   "outputs": [],
   "source": [
    "train_pos = pd.read_csv(\"data/train_Arabic_tweets_positive_20190413.tsv\", sep='\\t', names=[\"label\", \"tweet\"])\n",
    "train_neg = pd.read_csv(\"data/train_Arabic_tweets_negative_20190413.tsv\", sep='\\t', names=[\"label\", \"tweet\"])\n",
    "test_pos = pd.read_csv(\"data/test_Arabic_tweets_positive_20190413.tsv\", sep='\\t', names=[\"label\", \"tweet\"])\n",
    "test_neg = pd.read_csv(\"data/test_Arabic_tweets_negative_20190413.tsv\", sep='\\t', names=[\"label\", \"tweet\"])\n",
    "train = pd.concat([train_pos, train_neg]).sample(frac=.25, random_state=0)\n",
    "test = pd.concat([test_pos, test_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abf0ac73-68f4-4f33-ad8a-49e161e566dc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "abf0ac73-68f4-4f33-ad8a-49e161e566dc",
    "outputId": "edb027e6-18d4-4cc6-df4e-e4d706a0133d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15454</th>\n",
       "      <td>pos</td>\n",
       "      <td>يسلموو #آدآرتنآ مآقصرتوآ على آلدعم آلجميل تميز...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10789</th>\n",
       "      <td>pos</td>\n",
       "      <td>اللهم إن في صدري كلاما لا أستطيع ترتيبه في الد...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19949</th>\n",
       "      <td>neg</td>\n",
       "      <td>كم مره قعدت مع ناس او حتى شخص و اسولف معاهم و ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12259</th>\n",
       "      <td>neg</td>\n",
       "      <td>اسأل الله العظيم رب العرش العظيم ان يشفيك ي يا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8704</th>\n",
       "      <td>pos</td>\n",
       "      <td>اللهم شيئا لطيفا ، مفاجئ غير مخطط له ، يأتي من...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13929</th>\n",
       "      <td>pos</td>\n",
       "      <td>رسام الكاريكاتير وضع كل واحد في مكانه الطبيعي ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10355</th>\n",
       "      <td>neg</td>\n",
       "      <td>وشكلنا كده حنتغبن تاالت😭😭❤️</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9840</th>\n",
       "      <td>neg</td>\n",
       "      <td>#البريمي #من_قديم_عمان أحاتي طلابي يخافون من ص...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9545</th>\n",
       "      <td>neg</td>\n",
       "      <td>لأه لأه لأه تبقى معديه لأه.. ✋</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>pos</td>\n",
       "      <td>صبح علي بالخير و تحفاني يازين الصبح يوم انه بد...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11319 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                              tweet\n",
       "15454   pos  يسلموو #آدآرتنآ مآقصرتوآ على آلدعم آلجميل تميز...\n",
       "10789   pos  اللهم إن في صدري كلاما لا أستطيع ترتيبه في الد...\n",
       "19949   neg  كم مره قعدت مع ناس او حتى شخص و اسولف معاهم و ...\n",
       "12259   neg  اسأل الله العظيم رب العرش العظيم ان يشفيك ي يا...\n",
       "8704    pos  اللهم شيئا لطيفا ، مفاجئ غير مخطط له ، يأتي من...\n",
       "...     ...                                                ...\n",
       "13929   pos  رسام الكاريكاتير وضع كل واحد في مكانه الطبيعي ...\n",
       "10355   neg                        وشكلنا كده حنتغبن تاالت😭😭❤️\n",
       "9840    neg  #البريمي #من_قديم_عمان أحاتي طلابي يخافون من ص...\n",
       "9545    neg                     لأه لأه لأه تبقى معديه لأه.. ✋\n",
       "698     pos  صبح علي بالخير و تحفاني يازين الصبح يوم انه بد...\n",
       "\n",
       "[11319 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec34d35c-034b-4d11-8ea6-6767653d47b6",
   "metadata": {
    "id": "ec34d35c-034b-4d11-8ea6-6767653d47b6"
   },
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    text = araby.strip_harakat(text)\n",
    "    text = araby.strip_tashkeel(text)\n",
    "    text = araby.strip_small(text)\n",
    "    text = araby.strip_tatweel(text)\n",
    "    text = araby.strip_shadda(text)\n",
    "    text = araby.strip_diacritics(text)\n",
    "    text = araby.normalize_ligature(text)\n",
    "    #text = araby.normalize_hamza(text)\n",
    "    text = araby.normalize_teh(text)\n",
    "    text = araby.normalize_alef(text)\n",
    "    return text\n",
    "\n",
    "def strip_all(text):\n",
    "    l = [' ', '0', '1', '2', '3', '4', '5', '6',\n",
    "       '7', '8', '9', '?', \n",
    "       '؟', 'ء', 'ؤ', 'ئ', 'ا', 'ب', 'ت', 'ث',\n",
    "       'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ',\n",
    "       'ع', 'غ', 'ف', 'ق', 'ك', 'ل', 'م', 'ن', 'ه', 'و', 'ي', '٠', '١',\n",
    "       '٢', '٣', '٤', '٥', '٦', '٧', '٨', '٩']\n",
    "    return \"\".join([x for x in text if x in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ea115c1-fddf-49f7-ba66-db45bff6c844",
   "metadata": {
    "id": "6ea115c1-fddf-49f7-ba66-db45bff6c844"
   },
   "outputs": [],
   "source": [
    "train.tweet = train.tweet.apply(normalize).apply(strip_all).apply(araby.tokenize)\n",
    "test.tweet = test.tweet.apply(normalize).apply(strip_all).apply(araby.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5b6b7fb-6f01-4b77-9334-65fd3d346dc1",
   "metadata": {
    "id": "e5b6b7fb-6f01-4b77-9334-65fd3d346dc1"
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(train.label)\n",
    "train.label = le.transform(train.label)\n",
    "test.label = le.transform(test.label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e9c3e9a-66e2-45fa-915e-2475f3785d62",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "9e9c3e9a-66e2-45fa-915e-2475f3785d62",
    "outputId": "ba0f908d-ca2e-40aa-8ef2-124b00d16f2a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15454</th>\n",
       "      <td>1</td>\n",
       "      <td>[يسلموو, ادارتنا, ماقصرتوا, علا, الدعم, الجميل...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10789</th>\n",
       "      <td>1</td>\n",
       "      <td>[اللهم, ان, في, صدري, كلاما, لا, استطيع, ترتيب...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19949</th>\n",
       "      <td>0</td>\n",
       "      <td>[كم, مره, قعدت, مع, ناس, او, حتا, شخص, و, اسول...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12259</th>\n",
       "      <td>0</td>\n",
       "      <td>[اسال, الله, العظيم, رب, العرش, العظيم, ان, يش...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8704</th>\n",
       "      <td>1</td>\n",
       "      <td>[اللهم, شيئا, لطيفا, مفاجئ, غير, مخطط, له, يات...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13929</th>\n",
       "      <td>1</td>\n",
       "      <td>[رسام, الكاريكاتير, وضع, كل, واحد, في, مكانه, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10355</th>\n",
       "      <td>0</td>\n",
       "      <td>[وشكلنا, كده, حنتغبن, تاالت]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9840</th>\n",
       "      <td>0</td>\n",
       "      <td>[البريمي, منقديمعمان, احاتي, طلابي, يخافون, من...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9545</th>\n",
       "      <td>0</td>\n",
       "      <td>[لاه, لاه, لاه, تبقا, معديه, لاه]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>1</td>\n",
       "      <td>[صبح, علي, بالخير, و, تحفاني, يازين, الصبح, يو...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11319 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                              tweet\n",
       "15454      1  [يسلموو, ادارتنا, ماقصرتوا, علا, الدعم, الجميل...\n",
       "10789      1  [اللهم, ان, في, صدري, كلاما, لا, استطيع, ترتيب...\n",
       "19949      0  [كم, مره, قعدت, مع, ناس, او, حتا, شخص, و, اسول...\n",
       "12259      0  [اسال, الله, العظيم, رب, العرش, العظيم, ان, يش...\n",
       "8704       1  [اللهم, شيئا, لطيفا, مفاجئ, غير, مخطط, له, يات...\n",
       "...      ...                                                ...\n",
       "13929      1  [رسام, الكاريكاتير, وضع, كل, واحد, في, مكانه, ...\n",
       "10355      0                       [وشكلنا, كده, حنتغبن, تاالت]\n",
       "9840       0  [البريمي, منقديمعمان, احاتي, طلابي, يخافون, من...\n",
       "9545       0                  [لاه, لاه, لاه, تبقا, معديه, لاه]\n",
       "698        1  [صبح, علي, بالخير, و, تحفاني, يازين, الصبح, يو...\n",
       "\n",
       "[11319 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "environmental-palace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2idx(word, word_model):\n",
    "    return word_model.wv.key_to_index[word]\n",
    "def idx2word(idx):\n",
    "    return word_model.wv.index_to_key[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fresh-cleaners",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train.tweet.values, train.label.values, test_size=0.5,random_state=0, stratify=train.label.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00ed07d-8036-4e61-a7d9-bbefb19384d4",
   "metadata": {
    "id": "e00ed07d-8036-4e61-a7d9-bbefb19384d4"
   },
   "outputs": [],
   "source": [
    "def token2vec(word_model, data):\n",
    "    data_tmp = np.zeros([data.shape[0], 100], dtype=np.int32)\n",
    "    for i, sentence in enumerate(data):\n",
    "        for t, word in enumerate(sentence[:100]):\n",
    "            if word in word_model.wv.key_to_index:\n",
    "                data_tmp[i, t] = word2idx(word, word_model)\n",
    "            else:\n",
    "                data_tmp[i, t] = 0\n",
    "    return data_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00f81eee-3188-44cf-b1c1-06c0a9d5b7ef",
   "metadata": {
    "id": "00f81eee-3188-44cf-b1c1-06c0a9d5b7ef"
   },
   "outputs": [],
   "source": [
    "def train_model(vocab_size, embedding_size, weights):\n",
    "    model = Sequential()\n",
    "    #model.add(InputLayer((100,)))\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=emdedding_size, weights=[weights]))\n",
    "    model.add(Bidirectional(GRU(units = 32, return_sequences=True)))\n",
    "    model.add(Bidirectional(GRU(units = 32, return_sequences=False)))\n",
    "    model.add(Dense(16, activation = 'relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(2, activation = 'softmax'))\n",
    "    model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "    callbacks = [tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, min_delta=0.0001, min_lr=0.0001)]\n",
    "    model.fit(X_train, y_train, validation_data= (X_valid, y_valid), epochs = 5, batch_size= 128, shuffle = True, callbacks=callbacks)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ba0efc-2a73-480a-ba4f-92839c6c0ca3",
   "metadata": {
    "id": "b6ba0efc-2a73-480a-ba4f-92839c6c0ca3"
   },
   "outputs": [],
   "source": [
    "sentences = np.concatenate([train.tweet.values, test.tweet.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Xajhi20V-yM_",
   "metadata": {
    "id": "Xajhi20V-yM_"
   },
   "outputs": [],
   "source": [
    "!pip uninstall gensim\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ed6f2e-e8d2-4b25-ac8d-3a786b7b4578",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e3ed6f2e-e8d2-4b25-ac8d-3a786b7b4578",
    "outputId": "05ee279e-c12d-4f79-a392-b8f0d0018202"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "45/45 [==============================] - 11s 112ms/step - loss: 0.6647 - accuracy: 0.5835 - val_loss: 0.6233 - val_accuracy: 0.6627\n",
      "Epoch 2/5\n",
      "45/45 [==============================] - 3s 78ms/step - loss: 0.5843 - accuracy: 0.7035 - val_loss: 0.5831 - val_accuracy: 0.6928\n",
      "Epoch 3/5\n",
      "45/45 [==============================] - 3s 77ms/step - loss: 0.4309 - accuracy: 0.8123 - val_loss: 0.5790 - val_accuracy: 0.7035\n",
      "Epoch 4/5\n",
      "45/45 [==============================] - 4s 79ms/step - loss: 0.1872 - accuracy: 0.9304 - val_loss: 0.7249 - val_accuracy: 0.6899\n",
      "Epoch 5/5\n",
      "45/45 [==============================] - 3s 77ms/step - loss: 0.1038 - accuracy: 0.9671 - val_loss: 0.9354 - val_accuracy: 0.6977\n"
     ]
    }
   ],
   "source": [
    "word2vec_model = gensim.models.Word2Vec(sentences=sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "word2vec_model.build_vocab(sentences) \n",
    "word2vec_model.train(sentences, total_examples=word2vec_model.corpus_count, epochs=15)\n",
    "word2vec_weights = word2vec_model.syn1neg\n",
    "vocab_size, emdedding_size = word2vec_weights.shape\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train.tweet.values, train.label.values, test_size=0.5,random_state=0, stratify=train.label.values)\n",
    "X_train = token2vec(word2vec_model, X_train)\n",
    "X_valid = token2vec(word2vec_model, X_valid)\n",
    "\n",
    "trained_word2vec = train_model(vocab_size, emdedding_size, word2vec_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22645e1-3541-4909-81c0-3b1ebd0710b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f22645e1-3541-4909-81c0-3b1ebd0710b4",
    "outputId": "7f98e2d1-8884-4ae2-bfdb-811596ff25bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "45/45 [==============================] - 10s 113ms/step - loss: 0.6881 - accuracy: 0.5377 - val_loss: 0.6502 - val_accuracy: 0.6459\n",
      "Epoch 2/5\n",
      "45/45 [==============================] - 3s 77ms/step - loss: 0.5937 - accuracy: 0.6825 - val_loss: 0.5722 - val_accuracy: 0.6952\n",
      "Epoch 3/5\n",
      "45/45 [==============================] - 4s 79ms/step - loss: 0.3993 - accuracy: 0.8357 - val_loss: 0.5899 - val_accuracy: 0.7081\n",
      "Epoch 4/5\n",
      "45/45 [==============================] - 3s 77ms/step - loss: 0.1758 - accuracy: 0.9449 - val_loss: 0.7805 - val_accuracy: 0.6981\n",
      "Epoch 5/5\n",
      "45/45 [==============================] - 3s 77ms/step - loss: 0.0977 - accuracy: 0.9767 - val_loss: 0.8450 - val_accuracy: 0.6970\n"
     ]
    }
   ],
   "source": [
    "fasttext_model = gensim.models.FastText(sentences=sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "fasttext_model.build_vocab(sentences)\n",
    "fasttext_model.train(sentences, total_examples=fasttext_model.corpus_count, epochs=15) \n",
    "fasttext_weights = fasttext_model.syn1neg\n",
    "vocab_size, emdedding_size = fasttext_weights.shape\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train.tweet.values, train.label.values, test_size=0.5,random_state=0, stratify=train.label.values)\n",
    "X_train = token2vec(fasttext_model, X_train)\n",
    "X_valid = token2vec(fasttext_model, X_valid)\n",
    "\n",
    "trained_fasttext = train_model(vocab_size, emdedding_size, fasttext_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82199157-b59c-4a49-91be-9f6990f7d85d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "82199157-b59c-4a49-91be-9f6990f7d85d",
    "outputId": "e1ccdd0e-d1e3-43c2-86ac-cf66179a2738"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "45/45 [==============================] - 88s 2s/step - loss: 0.6935 - accuracy: 0.5277 - val_loss: 0.6807 - val_accuracy: 0.5175\n",
      "Epoch 2/5\n",
      "45/45 [==============================] - 86s 2s/step - loss: 0.6545 - accuracy: 0.6194 - val_loss: 0.6065 - val_accuracy: 0.6841\n",
      "Epoch 3/5\n",
      "45/45 [==============================] - 60s 1s/step - loss: 0.5203 - accuracy: 0.7466 - val_loss: 0.5830 - val_accuracy: 0.6903\n",
      "Epoch 4/5\n",
      "45/45 [==============================] - 60s 1s/step - loss: 0.3514 - accuracy: 0.8608 - val_loss: 0.6932 - val_accuracy: 0.6686\n",
      "Epoch 5/5\n",
      "45/45 [==============================] - 60s 1s/step - loss: 0.2076 - accuracy: 0.9275 - val_loss: 0.9247 - val_accuracy: 0.6859\n"
     ]
    }
   ],
   "source": [
    "word_model_cbow = gensim.models.KeyedVectors.load(\"full_grams_cbow_100_twitter.mdl\")\n",
    "word_model_cbow_weights = word_model_cbow.syn1neg\n",
    "vocab_size, emdedding_size = word_model_cbow_weights.shape\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train.tweet.values, train.label.values, test_size=0.5,random_state=0, stratify=train.label.values)\n",
    "\n",
    "X_train = token2vec(word_model_cbow, X_train)\n",
    "X_valid = token2vec(word_model_cbow, X_valid)\n",
    "\n",
    "trained_cbow = train_model(vocab_size, emdedding_size, word_model_cbow_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4f323d-9475-4970-b05c-d3eb0f8f4604",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fb4f323d-9475-4970-b05c-d3eb0f8f4604",
    "outputId": "03561197-5245-4cc6-cef0-1b37e2901e4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "45/45 [==============================] - 68s 1s/step - loss: 0.6678 - accuracy: 0.5914 - val_loss: 0.6203 - val_accuracy: 0.6693\n",
      "Epoch 2/5\n",
      "45/45 [==============================] - 59s 1s/step - loss: 0.5828 - accuracy: 0.6954 - val_loss: 0.5697 - val_accuracy: 0.7080\n",
      "Epoch 3/5\n",
      "45/45 [==============================] - 59s 1s/step - loss: 0.4745 - accuracy: 0.7910 - val_loss: 0.5520 - val_accuracy: 0.7200\n",
      "Epoch 4/5\n",
      "45/45 [==============================] - 59s 1s/step - loss: 0.3414 - accuracy: 0.8657 - val_loss: 0.6169 - val_accuracy: 0.7147\n",
      "Epoch 5/5\n",
      "45/45 [==============================] - 59s 1s/step - loss: 0.2231 - accuracy: 0.9200 - val_loss: 0.7915 - val_accuracy: 0.7011\n"
     ]
    }
   ],
   "source": [
    "word_model_skipgram = gensim.models.KeyedVectors.load(\"full_grams_sg_100_twitter.mdl\")\n",
    "word_model_skipgram_weights = word_model_skipgram.syn1neg\n",
    "vocab_size, emdedding_size = word_model_skipgram_weights.shape\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train.tweet.values, train.label.values, test_size=0.5,random_state=0, stratify=train.label.values)\n",
    "\n",
    "X_train = token2vec(word_model_skipgram, X_train)\n",
    "X_valid = token2vec(word_model_skipgram, X_valid)\n",
    "\n",
    "trained_skipgram = train_model(vocab_size, emdedding_size, word_model_skipgram_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6b17894-1140-4e18-a870-6ab8cc925d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "vocab = np.unique(np.array([x for y in train.tweet.values for x in y ]))\n",
    "word_index = {w: i for i, w in enumerate(vocab)}\n",
    "\n",
    "seq_list = []\n",
    "for words in train.tweet.values:\n",
    "    seq = []\n",
    "    for w in words:\n",
    "        seq.append(word_index.get(w,0))\n",
    "    seq_list.append(seq)\n",
    "train_padded = pad_sequences(seq_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "marine-leader",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "45/45 [==============================] - 14s 178ms/step - loss: 0.6775 - accuracy: 0.5748 - val_loss: 0.6280 - val_accuracy: 0.6587\n",
      "Epoch 2/5\n",
      "45/45 [==============================] - 7s 158ms/step - loss: 0.5919 - accuracy: 0.6874 - val_loss: 0.5765 - val_accuracy: 0.7011\n",
      "Epoch 3/5\n",
      "45/45 [==============================] - 7s 155ms/step - loss: 0.4941 - accuracy: 0.7728 - val_loss: 0.5551 - val_accuracy: 0.7141\n",
      "Epoch 4/5\n",
      "45/45 [==============================] - 7s 159ms/step - loss: 0.3664 - accuracy: 0.8448 - val_loss: 0.6142 - val_accuracy: 0.7129\n",
      "Epoch 5/5\n",
      "45/45 [==============================] - 7s 159ms/step - loss: 0.2418 - accuracy: 0.9085 - val_loss: 0.7280 - val_accuracy: 0.7159\n"
     ]
    }
   ],
   "source": [
    "from pretrained.AraVec import AraVec\n",
    "aravec = AraVec()\n",
    "model_path = aravec.get_model(\"Twitter_SkipGram_100\", unzip=True)\n",
    "model = aravec.load_model(model_path)\n",
    "\n",
    "\n",
    "embeddings_index = aravec.get_embedding_matrix(model)\n",
    "vocab_size, emdedding_size = len(word_index),100\n",
    "embeddings_matrix = aravec.load_embedding_matrix(vocab_size, emdedding_size, word_index, embeddings_index)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_padded, train.label.values, test_size=0.5,random_state=0, stratify=train.label.values)\n",
    "\n",
    "trained_skipgram = train_model(vocab_size, emdedding_size, embeddings_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2LA1_FOLJfco",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2LA1_FOLJfco",
    "outputId": "3181e854-802d-49ae-fe8a-046a88ac908a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed datasets-1.7.0 fsspec-2021.5.0 xxhash-2.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1070c0f1-e12d-4c72-b4da-adeabde772a8",
   "metadata": {
    "id": "1070c0f1-e12d-4c72-b4da-adeabde772a8"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "train = pd.concat([train_pos, train_neg])\n",
    "test = pd.concat([test_pos, test_neg])\n",
    "train.tweet = train.tweet.apply(normalize).apply(strip_all)\n",
    "test.tweet = test.tweet.apply(normalize).apply(strip_all)\n",
    "train.label = le.transform(train.label)\n",
    "test.label = le.transform(test.label)\n",
    "\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train.tweet, train.label, test_size=0.5,random_state=0, stratify=train.label.values)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"asafaya/bert-medium-arabic\")\n",
    "\n",
    "train_encodings = tokenizer(X_train.tolist(), truncation=True, padding='max_length', max_length=64)\n",
    "val_encodings = tokenizer(X_valid.tolist(), truncation=True, padding='max_length', max_length=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec61b626-2b8c-4c8e-9299-d48b299777b4",
   "metadata": {
    "id": "ec61b626-2b8c-4c8e-9299-d48b299777b4"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class MeterDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = MeterDataset(train_encodings, y_train.tolist())\n",
    "val_dataset = MeterDataset(val_encodings, y_valid.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d482df79-717e-430f-a461-a4aa0593fefe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370,
     "referenced_widgets": [
      "8a1c523e5a234220a6f0e1deab0e0083",
      "252b6a14984545a684aeaff90818c2ae",
      "ede198ccc18446b3a021f8f0d21294ff",
      "8fb5dd2f07cb4dcaad0a5d7dac81485f",
      "2dc4fa91529047369720a951d77e39e6",
      "1171428605b143d1bc00cee9e3ded25b",
      "b670450c54df49c7959a58a55ccd977d",
      "efd9a8f7521946f0b04681246bf6fb58"
     ]
    },
    "id": "d482df79-717e-430f-a461-a4aa0593fefe",
    "outputId": "6cb2d23a-c07d-41e1-e3ca-c00f2b94f180"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a1c523e5a234220a6f0e1deab0e0083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=169735531.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at asafaya/bert-medium-arabic were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at asafaya/bert-medium-arabic and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='708' max='708' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [708/708 08:58, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.518100</td>\n",
       "      <td>0.519620</td>\n",
       "      <td>0.738890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.407100</td>\n",
       "      <td>0.483000</td>\n",
       "      <td>0.767868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.528493</td>\n",
       "      <td>0.768707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.238100</td>\n",
       "      <td>0.565590</td>\n",
       "      <td>0.766720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=708, training_loss=0.3904402146568406, metrics={'train_runtime': 538.6668, 'train_samples_per_second': 1.314, 'total_flos': 430115838856704.0, 'epoch': 4.0, 'init_mem_cpu_alloc_delta': 0, 'init_mem_gpu_alloc_delta': 170887680, 'init_mem_cpu_peaked_delta': 0, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 3993600, 'train_mem_gpu_alloc_delta': 505741824, 'train_mem_cpu_peaked_delta': 0, 'train_mem_gpu_peaked_delta': 2774039040})"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForMaskedLM, AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"asafaya/bert-medium-arabic\", num_labels=2)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=4,              # total number of training epochs\n",
    "    per_device_train_batch_size=128,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=32,  #500              # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,           # strength of weight decay\n",
    "    learning_rate= 5e-5,\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy = 'epoch',\n",
    ")\n",
    "from datasets import load_metric\n",
    "from transformers import Trainer\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90664ac3-7056-47a9-a988-0592f5d0cab9",
   "metadata": {
    "id": "90664ac3-7056-47a9-a988-0592f5d0cab9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51966f6c-74cf-4467-b423-9edc0922e511",
   "metadata": {
    "id": "51966f6c-74cf-4467-b423-9edc0922e511"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Demo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1171428605b143d1bc00cee9e3ded25b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "252b6a14984545a684aeaff90818c2ae": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2dc4fa91529047369720a951d77e39e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "8a1c523e5a234220a6f0e1deab0e0083": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ede198ccc18446b3a021f8f0d21294ff",
       "IPY_MODEL_8fb5dd2f07cb4dcaad0a5d7dac81485f"
      ],
      "layout": "IPY_MODEL_252b6a14984545a684aeaff90818c2ae"
     }
    },
    "8fb5dd2f07cb4dcaad0a5d7dac81485f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_efd9a8f7521946f0b04681246bf6fb58",
      "placeholder": "​",
      "style": "IPY_MODEL_b670450c54df49c7959a58a55ccd977d",
      "value": " 170M/170M [00:09&lt;00:00, 18.5MB/s]"
     }
    },
    "b670450c54df49c7959a58a55ccd977d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ede198ccc18446b3a021f8f0d21294ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1171428605b143d1bc00cee9e3ded25b",
      "max": 169735531,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2dc4fa91529047369720a951d77e39e6",
      "value": 169735531
     }
    },
    "efd9a8f7521946f0b04681246bf6fb58": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
