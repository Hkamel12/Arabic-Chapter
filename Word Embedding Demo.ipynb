{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca1f1e76-aab8-420a-a32b-5e7793b75aef",
   "metadata": {
    "id": "ca1f1e76-aab8-420a-a32b-5e7793b75aef"
   },
   "source": [
    "<h1>Task 8: Word Embedding</h1>\n",
    "\n",
    "<h4> This notebook compares different embedding methods on a simple task (sentiment analysis) <a href=\"https://www.kaggle.com/mksaad/arabic-sentiment-twitter-corpus\">on a small dataset</a>.</h4>\n",
    "\n",
    "<h4>Table of Contents:</h4>\n",
    "<ol>\n",
    "    <li>Load Dataset</li>\n",
    "    <li>Normalize Dataset</li>\n",
    "    <li>Tokenize Dataset</li>\n",
    "    <li>Word Embedding</li>\n",
    "    <li>Train RNN model</li>\n",
    "    <li>Evaluate model</li>\n",
    "</ol>\n",
    "<h4>Embedding Methods:</h4>\n",
    "<ol>\n",
    "    <li>Genism library's Word2Vec implementation (trained from scratch)</li>\n",
    "    <li>Genism library's fasttext implementation (trained from scratch)</li>\n",
    "    <li>AraVec pretrained embeddings</li>\n",
    "    <li>BERT Arabic pretrained model</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44dd0846-7c49-4358-a38a-43ce6c730c37",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "44dd0846-7c49-4358-a38a-43ce6c730c37",
    "outputId": "6777836f-e59e-47f2-9ed2-798a9d92416e"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import glob\n",
    "import gensim\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import shuffle\n",
    "from pyarabic import araby\n",
    "from tensorflow.keras.layers import LSTM, GRU, Embedding, Dense, Input, InputLayer, Dropout, Bidirectional, BatchNormalization, Flatten, Reshape\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53cd5e5-08d7-4614-97cf-90e86c805069",
   "metadata": {
    "id": "d53cd5e5-08d7-4614-97cf-90e86c805069"
   },
   "source": [
    "<h1>Load Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0753d856-c632-4660-b903-512d7385b43c",
   "metadata": {
    "id": "0753d856-c632-4660-b903-512d7385b43c"
   },
   "outputs": [],
   "source": [
    "train_pos = pd.read_csv(\"data/train_Arabic_tweets_positive_20190413.tsv\", sep='\\t', names=[\"label\", \"tweet\"])\n",
    "train_neg = pd.read_csv(\"data/train_Arabic_tweets_negative_20190413.tsv\", sep='\\t', names=[\"label\", \"tweet\"])\n",
    "test_pos = pd.read_csv(\"data/test_Arabic_tweets_positive_20190413.tsv\", sep='\\t', names=[\"label\", \"tweet\"])\n",
    "test_neg = pd.read_csv(\"data/test_Arabic_tweets_negative_20190413.tsv\", sep='\\t', names=[\"label\", \"tweet\"])\n",
    "train = pd.concat([train_pos, train_neg]).sample(frac=1.0, random_state=0)\n",
    "test = pd.concat([test_pos, test_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abf0ac73-68f4-4f33-ad8a-49e161e566dc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "abf0ac73-68f4-4f33-ad8a-49e161e566dc",
    "outputId": "edb027e6-18d4-4cc6-df4e-e4d706a0133d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15454</th>\n",
       "      <td>pos</td>\n",
       "      <td>يسلموو #آدآرتنآ مآقصرتوآ على آلدعم آلجميل تميز...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10789</th>\n",
       "      <td>pos</td>\n",
       "      <td>اللهم إن في صدري كلاما لا أستطيع ترتيبه في الد...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19949</th>\n",
       "      <td>neg</td>\n",
       "      <td>كم مره قعدت مع ناس او حتى شخص و اسولف معاهم و ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12259</th>\n",
       "      <td>neg</td>\n",
       "      <td>اسأل الله العظيم رب العرش العظيم ان يشفيك ي يا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8704</th>\n",
       "      <td>pos</td>\n",
       "      <td>اللهم شيئا لطيفا ، مفاجئ غير مخطط له ، يأتي من...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7642</th>\n",
       "      <td>neg</td>\n",
       "      <td>اذا الفيفا عارف هالشي غلط مش المفروض يتصرف ويت...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21243</th>\n",
       "      <td>pos</td>\n",
       "      <td>اللهم اجعلنا ممن تفائل بخيرك فأكرمته ، وتوكل ع...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19852</th>\n",
       "      <td>neg</td>\n",
       "      <td>صبر انظم لكم من الابتوب 😏</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20806</th>\n",
       "      <td>neg</td>\n",
       "      <td>والله توحشتها ايا سيدي ياه حابين هكا 😖</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>pos</td>\n",
       "      <td>بمناسبة فوز الهلال .. 💙 سحب على آيفون XR📱 رتوي...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45275 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                              tweet\n",
       "15454   pos  يسلموو #آدآرتنآ مآقصرتوآ على آلدعم آلجميل تميز...\n",
       "10789   pos  اللهم إن في صدري كلاما لا أستطيع ترتيبه في الد...\n",
       "19949   neg  كم مره قعدت مع ناس او حتى شخص و اسولف معاهم و ...\n",
       "12259   neg  اسأل الله العظيم رب العرش العظيم ان يشفيك ي يا...\n",
       "8704    pos  اللهم شيئا لطيفا ، مفاجئ غير مخطط له ، يأتي من...\n",
       "...     ...                                                ...\n",
       "7642    neg  اذا الفيفا عارف هالشي غلط مش المفروض يتصرف ويت...\n",
       "21243   pos  اللهم اجعلنا ممن تفائل بخيرك فأكرمته ، وتوكل ع...\n",
       "19852   neg                          صبر انظم لكم من الابتوب 😏\n",
       "20806   neg             والله توحشتها ايا سيدي ياه حابين هكا 😖\n",
       "2732    pos  بمناسبة فوز الهلال .. 💙 سحب على آيفون XR📱 رتوي...\n",
       "\n",
       "[45275 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec34d35c-034b-4d11-8ea6-6767653d47b6",
   "metadata": {
    "id": "ec34d35c-034b-4d11-8ea6-6767653d47b6"
   },
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    text = araby.strip_harakat(text)\n",
    "    text = araby.strip_tashkeel(text)\n",
    "    text = araby.strip_small(text)\n",
    "    text = araby.strip_tatweel(text)\n",
    "    text = araby.strip_shadda(text)\n",
    "    text = araby.strip_diacritics(text)\n",
    "    text = araby.normalize_ligature(text)\n",
    "    #text = araby.normalize_hamza(text)\n",
    "    text = araby.normalize_teh(text)\n",
    "    text = araby.normalize_alef(text)\n",
    "    return text\n",
    "\n",
    "def strip_all(text):\n",
    "    l = [' ', '0', '1', '2', '3', '4', '5', '6',\n",
    "       '7', '8', '9', '?', \n",
    "       '؟', 'ء', 'ؤ', 'ئ', 'ا', 'ب', 'ت', 'ث',\n",
    "       'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ',\n",
    "       'ع', 'غ', 'ف', 'ق', 'ك', 'ل', 'م', 'ن', 'ه', 'و', 'ي', '٠', '١',\n",
    "       '٢', '٣', '٤', '٥', '٦', '٧', '٨', '٩']\n",
    "    return \"\".join([x for x in text if x in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ea115c1-fddf-49f7-ba66-db45bff6c844",
   "metadata": {
    "id": "6ea115c1-fddf-49f7-ba66-db45bff6c844"
   },
   "outputs": [],
   "source": [
    "train.tweet = train.tweet.apply(normalize).apply(strip_all).apply(araby.tokenize)\n",
    "test.tweet = test.tweet.apply(normalize).apply(strip_all).apply(araby.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5b6b7fb-6f01-4b77-9334-65fd3d346dc1",
   "metadata": {
    "id": "e5b6b7fb-6f01-4b77-9334-65fd3d346dc1"
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(train.label)\n",
    "train.label = le.transform(train.label)\n",
    "test.label = le.transform(test.label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e9c3e9a-66e2-45fa-915e-2475f3785d62",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "9e9c3e9a-66e2-45fa-915e-2475f3785d62",
    "outputId": "ba0f908d-ca2e-40aa-8ef2-124b00d16f2a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15454</th>\n",
       "      <td>1</td>\n",
       "      <td>[يسلموو, ادارتنا, ماقصرتوا, علا, الدعم, الجميل...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10789</th>\n",
       "      <td>1</td>\n",
       "      <td>[اللهم, ان, في, صدري, كلاما, لا, استطيع, ترتيب...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19949</th>\n",
       "      <td>0</td>\n",
       "      <td>[كم, مره, قعدت, مع, ناس, او, حتا, شخص, و, اسول...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12259</th>\n",
       "      <td>0</td>\n",
       "      <td>[اسال, الله, العظيم, رب, العرش, العظيم, ان, يش...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8704</th>\n",
       "      <td>1</td>\n",
       "      <td>[اللهم, شيئا, لطيفا, مفاجئ, غير, مخطط, له, يات...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7642</th>\n",
       "      <td>0</td>\n",
       "      <td>[اذا, الفيفا, عارف, هالشي, غلط, مش, المفروض, ي...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21243</th>\n",
       "      <td>1</td>\n",
       "      <td>[اللهم, اجعلنا, ممن, تفائل, بخيرك, فاكرمته, وت...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19852</th>\n",
       "      <td>0</td>\n",
       "      <td>[صبر, انظم, لكم, من, الابتوب]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20806</th>\n",
       "      <td>0</td>\n",
       "      <td>[والله, توحشتها, ايا, سيدي, ياه, حابين, هكا]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>1</td>\n",
       "      <td>[بمناسبه, فوز, الهلال, سحب, علا, ايفون, رتويت,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45275 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                              tweet\n",
       "15454      1  [يسلموو, ادارتنا, ماقصرتوا, علا, الدعم, الجميل...\n",
       "10789      1  [اللهم, ان, في, صدري, كلاما, لا, استطيع, ترتيب...\n",
       "19949      0  [كم, مره, قعدت, مع, ناس, او, حتا, شخص, و, اسول...\n",
       "12259      0  [اسال, الله, العظيم, رب, العرش, العظيم, ان, يش...\n",
       "8704       1  [اللهم, شيئا, لطيفا, مفاجئ, غير, مخطط, له, يات...\n",
       "...      ...                                                ...\n",
       "7642       0  [اذا, الفيفا, عارف, هالشي, غلط, مش, المفروض, ي...\n",
       "21243      1  [اللهم, اجعلنا, ممن, تفائل, بخيرك, فاكرمته, وت...\n",
       "19852      0                      [صبر, انظم, لكم, من, الابتوب]\n",
       "20806      0       [والله, توحشتها, ايا, سيدي, ياه, حابين, هكا]\n",
       "2732       1  [بمناسبه, فوز, الهلال, سحب, علا, ايفون, رتويت,...\n",
       "\n",
       "[45275 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "environmental-palace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2idx(word, word_model):\n",
    "    return word_model.wv.key_to_index[word]\n",
    "def idx2word(idx):\n",
    "    return word_model.wv.index_to_key[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fresh-cleaners",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train.tweet.values, train.label.values, test_size=0.5,random_state=0, stratify=train.label.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e00ed07d-8036-4e61-a7d9-bbefb19384d4",
   "metadata": {
    "id": "e00ed07d-8036-4e61-a7d9-bbefb19384d4"
   },
   "outputs": [],
   "source": [
    "def token2vec(word_model, data):\n",
    "    data_tmp = np.zeros([data.shape[0], 100], dtype=np.int32)\n",
    "    for i, sentence in enumerate(data):\n",
    "        for t, word in enumerate(sentence[:100]):\n",
    "            if word in word_model.wv.key_to_index:\n",
    "                data_tmp[i, t] = word2idx(word, word_model)\n",
    "            else:\n",
    "                data_tmp[i, t] = 0\n",
    "    return data_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00f81eee-3188-44cf-b1c1-06c0a9d5b7ef",
   "metadata": {
    "id": "00f81eee-3188-44cf-b1c1-06c0a9d5b7ef"
   },
   "outputs": [],
   "source": [
    "def train_model(vocab_size, embedding_size, weights):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=emdedding_size, weights=[weights], trainable=True))\n",
    "    model.add(Bidirectional(GRU(units = 32, return_sequences=True)))\n",
    "    model.add(Bidirectional(GRU(units = 32, return_sequences=False)))\n",
    "    model.add(Dense(16, activation = 'relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(2, activation = 'softmax'))\n",
    "    model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "    callbacks = [tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, min_delta=0.0001, min_lr=0.0001)]\n",
    "    model.fit(X_train, y_train, validation_data= (X_valid, y_valid), epochs = 5, batch_size= 128, shuffle = True, callbacks=callbacks)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6ba0efc-2a73-480a-ba4f-92839c6c0ca3",
   "metadata": {
    "id": "b6ba0efc-2a73-480a-ba4f-92839c6c0ca3"
   },
   "outputs": [],
   "source": [
    "sentences = np.concatenate([train.tweet.values, test.tweet.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dd0caf2-82aa-4b02-bb30-dedefe14ac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model_cbow = gensim.models.Word2Vec(sentences=sentences, vector_size=100, window=5, min_count=1, workers=4, seed=0)\n",
    "word2vec_model_cbow.build_vocab(sentences) \n",
    "word2vec_model_cbow.train(sentences, total_examples=word2vec_model_cbow.corpus_count, epochs=15)\n",
    "word2vec_weights_cbow = word2vec_model_cbow.syn1neg\n",
    "vocab_size, emdedding_size = word2vec_weights_cbow.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30c10f2d-86f5-43c4-9eec-971a95a8eb63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('الحقيقيه', 0.6934918165206909),\n",
       " ('احيانا', 0.6874623894691467),\n",
       " ('حكايه', 0.6851267218589783),\n",
       " ('الكتمان', 0.676027774810791),\n",
       " ('بكرامه', 0.6758304238319397),\n",
       " ('الموجعه', 0.6753607988357544),\n",
       " ('لانا', 0.6732767820358276),\n",
       " ('ندا', 0.6690214276313782),\n",
       " ('ارواح', 0.6672318577766418),\n",
       " ('يحسون', 0.6625495553016663)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model_cbow.wv.most_similar(\"لغه\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "593f78d2-520a-4e24-8767-16daec4e2edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('مفردات', 0.7585998177528381),\n",
       " ('لغات', 0.755275309085846),\n",
       " ('ولغه', 0.7323259711265564),\n",
       " ('ابجديه', 0.7260634899139404),\n",
       " ('مصطلحات', 0.7094709873199463),\n",
       " ('اللغه', 0.7051507234573364),\n",
       " ('ابجديات', 0.6975376605987549),\n",
       " ('بلغه', 0.6946367025375366),\n",
       " ('لغتها', 0.6932260394096375),\n",
       " ('ثقافه', 0.6907159090042114)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pretrained.AraVec import AraVec\n",
    "aravec = AraVec()\n",
    "model = aravec.load_model(\"full_grams_cbow_100_twitter/full_grams_cbow_100_twitter.mdl\")\n",
    "model.wv.most_similar(\"لغه\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3ed6f2e-e8d2-4b25-ac8d-3a786b7b4578",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e3ed6f2e-e8d2-4b25-ac8d-3a786b7b4578",
    "outputId": "05ee279e-c12d-4f79-a392-b8f0d0018202"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "177/177 [==============================] - 16s 70ms/step - loss: 0.6142 - accuracy: 0.6511 - val_loss: 0.5274 - val_accuracy: 0.7279\n",
      "Epoch 2/5\n",
      "177/177 [==============================] - 11s 65ms/step - loss: 0.4243 - accuracy: 0.8073 - val_loss: 0.4828 - val_accuracy: 0.7583\n",
      "Epoch 3/5\n",
      "177/177 [==============================] - 12s 65ms/step - loss: 0.2309 - accuracy: 0.9120 - val_loss: 0.5850 - val_accuracy: 0.7621\n",
      "Epoch 4/5\n",
      "177/177 [==============================] - 12s 70ms/step - loss: 0.1334 - accuracy: 0.9549 - val_loss: 0.7050 - val_accuracy: 0.7574\n",
      "Epoch 5/5\n",
      "177/177 [==============================] - 11s 65ms/step - loss: 0.0827 - accuracy: 0.9724 - val_loss: 0.8357 - val_accuracy: 0.7586\n"
     ]
    }
   ],
   "source": [
    "word2vec_model_cbow = gensim.models.Word2Vec(sentences=sentences, vector_size=100, window=5, min_count=1, workers=4, seed=0)\n",
    "word2vec_model_cbow.build_vocab(sentences) \n",
    "word2vec_model_cbow.train(sentences, total_examples=word2vec_model_cbow.corpus_count, epochs=15)\n",
    "word2vec_weights_cbow = word2vec_model_cbow.syn1neg\n",
    "vocab_size, emdedding_size = word2vec_weights_cbow.shape\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train.tweet.values, train.label.values, test_size=0.5,random_state=0, stratify=train.label.values)\n",
    "X_train = token2vec(word2vec_model_cbow, X_train)\n",
    "X_valid = token2vec(word2vec_model_cbow, X_valid)\n",
    "\n",
    "trained_word2vec_cbow = train_model(vocab_size, emdedding_size, word2vec_weights_cbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d689b554-b3d7-4a43-9649-f071745a6a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "177/177 [==============================] - 17s 71ms/step - loss: 0.6154 - accuracy: 0.6542 - val_loss: 0.5518 - val_accuracy: 0.7089\n",
      "Epoch 2/5\n",
      "177/177 [==============================] - 12s 65ms/step - loss: 0.4851 - accuracy: 0.7635 - val_loss: 0.4901 - val_accuracy: 0.7495\n",
      "Epoch 3/5\n",
      "177/177 [==============================] - 11s 65ms/step - loss: 0.3172 - accuracy: 0.8631 - val_loss: 0.5052 - val_accuracy: 0.7645\n",
      "Epoch 4/5\n",
      "177/177 [==============================] - 12s 65ms/step - loss: 0.1694 - accuracy: 0.9341 - val_loss: 0.6379 - val_accuracy: 0.7621\n",
      "Epoch 5/5\n",
      "177/177 [==============================] - 11s 65ms/step - loss: 0.0928 - accuracy: 0.9672 - val_loss: 0.7804 - val_accuracy: 0.7635\n"
     ]
    }
   ],
   "source": [
    "word2vec_model_sg = gensim.models.Word2Vec(sentences=sentences, vector_size=100, window=5, min_count=1, workers=4, seed=0, sg=1)\n",
    "word2vec_model_sg.build_vocab(sentences) \n",
    "word2vec_model_sg.train(sentences, total_examples=word2vec_model_sg.corpus_count, epochs=15)\n",
    "word2vec_weights_sg = word2vec_model_sg.syn1neg\n",
    "vocab_size, emdedding_size = word2vec_weights_sg.shape\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train.tweet.values, train.label.values, test_size=0.5,random_state=0, stratify=train.label.values)\n",
    "X_train = token2vec(word2vec_model_sg, X_train)\n",
    "X_valid = token2vec(word2vec_model_sg, X_valid)\n",
    "\n",
    "trained_word2vec_sg = train_model(vocab_size, emdedding_size, word2vec_weights_sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f22645e1-3541-4909-81c0-3b1ebd0710b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f22645e1-3541-4909-81c0-3b1ebd0710b4",
    "outputId": "7f98e2d1-8884-4ae2-bfdb-811596ff25bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "177/177 [==============================] - 16s 69ms/step - loss: 0.6071 - accuracy: 0.6525 - val_loss: 0.5213 - val_accuracy: 0.7268\n",
      "Epoch 2/5\n",
      "177/177 [==============================] - 11s 63ms/step - loss: 0.4151 - accuracy: 0.8100 - val_loss: 0.4658 - val_accuracy: 0.7661\n",
      "Epoch 3/5\n",
      "177/177 [==============================] - 12s 65ms/step - loss: 0.2260 - accuracy: 0.9111 - val_loss: 0.5864 - val_accuracy: 0.7700\n",
      "Epoch 4/5\n",
      "177/177 [==============================] - 12s 67ms/step - loss: 0.1271 - accuracy: 0.9549 - val_loss: 0.7278 - val_accuracy: 0.7650\n",
      "Epoch 5/5\n",
      "177/177 [==============================] - 11s 62ms/step - loss: 0.0724 - accuracy: 0.9755 - val_loss: 0.8025 - val_accuracy: 0.7650\n"
     ]
    }
   ],
   "source": [
    "fasttext_model = gensim.models.FastText(sentences=sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "fasttext_model.build_vocab(sentences)\n",
    "fasttext_model.train(sentences, total_examples=fasttext_model.corpus_count, epochs=15) \n",
    "fasttext_weights = fasttext_model.syn1neg\n",
    "vocab_size, emdedding_size = fasttext_weights.shape\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train.tweet.values, train.label.values, test_size=0.5,random_state=0, stratify=train.label.values)\n",
    "X_train = token2vec(fasttext_model, X_train)\n",
    "X_valid = token2vec(fasttext_model, X_valid)\n",
    "\n",
    "trained_fasttext = train_model(vocab_size, emdedding_size, fasttext_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6b17894-1140-4e18-a870-6ab8cc925d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "vocab = np.unique(np.array([x for y in train.tweet.values for x in y ]))\n",
    "word_index = {w: i for i, w in enumerate(vocab)}\n",
    "\n",
    "seq_list = []\n",
    "for words in train.tweet.values:\n",
    "    seq = []\n",
    "    for w in words:\n",
    "        seq.append(word_index.get(w,0))\n",
    "    seq_list.append(seq)\n",
    "train_padded = pad_sequences(seq_list, padding=\"post\", truncating=\"post\", maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd7d100e-37a0-4649-a0d1-115208fbac04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "177/177 [==============================] - 17s 68ms/step - loss: 0.6055 - accuracy: 0.6737 - val_loss: 0.5433 - val_accuracy: 0.7218\n",
      "Epoch 2/5\n",
      "177/177 [==============================] - 11s 61ms/step - loss: 0.5080 - accuracy: 0.7530 - val_loss: 0.5041 - val_accuracy: 0.7449\n",
      "Epoch 3/5\n",
      "177/177 [==============================] - 11s 60ms/step - loss: 0.4164 - accuracy: 0.8111 - val_loss: 0.4854 - val_accuracy: 0.7673\n",
      "Epoch 4/5\n",
      "177/177 [==============================] - 11s 61ms/step - loss: 0.3220 - accuracy: 0.8582 - val_loss: 0.5181 - val_accuracy: 0.7733\n",
      "Epoch 5/5\n",
      "177/177 [==============================] - 11s 60ms/step - loss: 0.2401 - accuracy: 0.8987 - val_loss: 0.5903 - val_accuracy: 0.7642\n"
     ]
    }
   ],
   "source": [
    "from pretrained.AraVec import AraVec\n",
    "aravec = AraVec()\n",
    "model_path = aravec.get_model(\"Twitter_CBOW_100\", unzip=True)\n",
    "model = aravec.load_model(model_path)\n",
    "\n",
    "embeddings_index = aravec.get_embedding_matrix(model)\n",
    "vocab_size, emdedding_size = len(word_index),100\n",
    "embeddings_matrix = aravec.load_embedding_matrix(vocab_size, emdedding_size, word_index, embeddings_index)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_padded, train.label.values, test_size=0.5,random_state=0, stratify=train.label.values)\n",
    "\n",
    "trained_cbow = train_model(vocab_size, emdedding_size, embeddings_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "marine-leader",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "177/177 [==============================] - 19s 72ms/step - loss: 0.6165 - accuracy: 0.6501 - val_loss: 0.5195 - val_accuracy: 0.7402\n",
      "Epoch 2/5\n",
      "177/177 [==============================] - 11s 63ms/step - loss: 0.4561 - accuracy: 0.7857 - val_loss: 0.4653 - val_accuracy: 0.7718\n",
      "Epoch 3/5\n",
      "177/177 [==============================] - 12s 67ms/step - loss: 0.3203 - accuracy: 0.8620 - val_loss: 0.5041 - val_accuracy: 0.7753\n",
      "Epoch 4/5\n",
      "177/177 [==============================] - 13s 72ms/step - loss: 0.1999 - accuracy: 0.9234 - val_loss: 0.6139 - val_accuracy: 0.7686\n",
      "Epoch 5/5\n",
      "177/177 [==============================] - 11s 62ms/step - loss: 0.1110 - accuracy: 0.9621 - val_loss: 0.7417 - val_accuracy: 0.7703\n"
     ]
    }
   ],
   "source": [
    "from pretrained.AraVec import AraVec\n",
    "aravec = AraVec()\n",
    "model_path = aravec.get_model(\"Twitter_SkipGram_100\", unzip=True)\n",
    "model = aravec.load_model(model_path)\n",
    "\n",
    "embeddings_index = aravec.get_embedding_matrix(model)\n",
    "vocab_size, emdedding_size = len(word_index),100\n",
    "embeddings_matrix = aravec.load_embedding_matrix(vocab_size, emdedding_size, word_index, embeddings_index)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_padded, train.label.values, test_size=0.5,random_state=0, stratify=train.label.values)\n",
    "\n",
    "trained_skipgram = train_model(vocab_size, emdedding_size, embeddings_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2LA1_FOLJfco",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2LA1_FOLJfco",
    "outputId": "3181e854-802d-49ae-fe8a-046a88ac908a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed datasets-1.7.0 fsspec-2021.5.0 xxhash-2.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1070c0f1-e12d-4c72-b4da-adeabde772a8",
   "metadata": {
    "id": "1070c0f1-e12d-4c72-b4da-adeabde772a8"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "train = pd.concat([train_pos, train_neg])\n",
    "test = pd.concat([test_pos, test_neg])\n",
    "train.tweet = train.tweet.apply(normalize).apply(strip_all)\n",
    "test.tweet = test.tweet.apply(normalize).apply(strip_all)\n",
    "train.label = le.transform(train.label)\n",
    "test.label = le.transform(test.label)\n",
    "\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train.tweet, train.label, test_size=0.5,random_state=0, stratify=train.label.values)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"asafaya/bert-medium-arabic\")\n",
    "\n",
    "train_encodings = tokenizer(X_train.tolist(), truncation=True, padding='max_length', max_length=100)\n",
    "val_encodings = tokenizer(X_valid.tolist(), truncation=True, padding='max_length', max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec61b626-2b8c-4c8e-9299-d48b299777b4",
   "metadata": {
    "id": "ec61b626-2b8c-4c8e-9299-d48b299777b4"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class MeterDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = MeterDataset(train_encodings, y_train.tolist())\n",
    "val_dataset = MeterDataset(val_encodings, y_valid.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d482df79-717e-430f-a461-a4aa0593fefe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370,
     "referenced_widgets": [
      "8a1c523e5a234220a6f0e1deab0e0083",
      "252b6a14984545a684aeaff90818c2ae",
      "ede198ccc18446b3a021f8f0d21294ff",
      "8fb5dd2f07cb4dcaad0a5d7dac81485f",
      "2dc4fa91529047369720a951d77e39e6",
      "1171428605b143d1bc00cee9e3ded25b",
      "b670450c54df49c7959a58a55ccd977d",
      "efd9a8f7521946f0b04681246bf6fb58"
     ]
    },
    "id": "d482df79-717e-430f-a461-a4aa0593fefe",
    "outputId": "6cb2d23a-c07d-41e1-e3ca-c00f2b94f180"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at asafaya/bert-medium-arabic were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at asafaya/bert-medium-arabic and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the latest cached version of the module from /home/mmi333/.cache/huggingface/modules/datasets_modules/metrics/accuracy/d60e08bd37e7c5a7bcc3620dd0d2788d25d233238ee0bdb3cfabde6c43d60574 (last modified on Wed Jun  2 15:47:30 2021) since it couldn't be found locally at accuracy/accuracy.py or remotely (ConnectionError).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2832' max='2832' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2832/2832 16:48, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.540600</td>\n",
       "      <td>0.499445</td>\n",
       "      <td>0.745251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.402000</td>\n",
       "      <td>0.486501</td>\n",
       "      <td>0.770960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.268000</td>\n",
       "      <td>0.570267</td>\n",
       "      <td>0.766543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.200300</td>\n",
       "      <td>0.751087</td>\n",
       "      <td>0.767073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2832, training_loss=0.33862685039639473, metrics={'train_runtime': 1008.9977, 'train_samples_per_second': 2.807, 'total_flos': 268079209398000.0, 'epoch': 4.0, 'init_mem_cpu_alloc_delta': 1894203392, 'init_mem_gpu_alloc_delta': 168528384, 'init_mem_cpu_peaked_delta': 64856064, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 20869120, 'train_mem_gpu_alloc_delta': 506130432, 'train_mem_cpu_peaked_delta': 130834432, 'train_mem_gpu_peaked_delta': 1205711360})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForMaskedLM, AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"asafaya/bert-medium-arabic\", num_labels=2)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=4,              # total number of training epochs\n",
    "    per_device_train_batch_size=32,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=32,              # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,           # strength of weight decay\n",
    "    learning_rate= 5e-5,\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy = 'epoch',\n",
    ")\n",
    "from datasets import load_metric\n",
    "from transformers import Trainer\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51966f6c-74cf-4467-b423-9edc0922e511",
   "metadata": {
    "id": "51966f6c-74cf-4467-b423-9edc0922e511"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Demo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1171428605b143d1bc00cee9e3ded25b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "252b6a14984545a684aeaff90818c2ae": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2dc4fa91529047369720a951d77e39e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "8a1c523e5a234220a6f0e1deab0e0083": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ede198ccc18446b3a021f8f0d21294ff",
       "IPY_MODEL_8fb5dd2f07cb4dcaad0a5d7dac81485f"
      ],
      "layout": "IPY_MODEL_252b6a14984545a684aeaff90818c2ae"
     }
    },
    "8fb5dd2f07cb4dcaad0a5d7dac81485f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_efd9a8f7521946f0b04681246bf6fb58",
      "placeholder": "​",
      "style": "IPY_MODEL_b670450c54df49c7959a58a55ccd977d",
      "value": " 170M/170M [00:09&lt;00:00, 18.5MB/s]"
     }
    },
    "b670450c54df49c7959a58a55ccd977d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ede198ccc18446b3a021f8f0d21294ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1171428605b143d1bc00cee9e3ded25b",
      "max": 169735531,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2dc4fa91529047369720a951d77e39e6",
      "value": 169735531
     }
    },
    "efd9a8f7521946f0b04681246bf6fb58": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
